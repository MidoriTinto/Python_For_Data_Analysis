{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.2 Working with Strings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MidoriTinto/Python_Fundamentals/blob/main/2_2_Working_with_Strings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdT0fwTCa4gI"
      },
      "source": [
        "# Working with Strings\n",
        "---\n",
        "\n",
        "The pandas library has a similar set of string functions to those available in python generally.  Because we often want to perform operations on a whole series of data values in a dataframe, we can use pandas string functions to do this:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozWLM6Pfa7d_"
      },
      "source": [
        "### Splitting data \n",
        "---\n",
        "\n",
        "Series.str.split() *to split a column's strings into components*    \n",
        "Series.str.get() *to get one of the components after the split*  \n",
        "\n",
        "You can **daisychain** these together:   \n",
        "\n",
        "`Series.str.split().str.get()`\n",
        "\n",
        "* `split()` will split by white space unless specified, for example if you wanted to split by \"/\" you would use `split(\"/\")`  \n",
        "\n",
        "* `get()` requires a parameter of the value position of the string you would like to 'get'. If you want the first word eg 1999, use `get(0)`.\n",
        "\n",
        "\n",
        "*Hint: remember to save your result into a new column* \n",
        "\n",
        "### Exercise 1 strings\n",
        "---\n",
        "\n",
        "Let's use the data set 'Housing in London' at 'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv'\n",
        "\n",
        "The date, in this dataset is a string.   To filter for a particular year, we will need to extract the first four letters as a substring.  We can create a new column called **year**, which just contains the year, stored as a number.\n",
        "\n",
        "The date is written in the format yyyy-mm-dd.  We can split the year around the '-' and then use the first component.\n",
        "\n",
        "\n",
        "Create a function called **get_year()** which splits the data from the date column, and creates a year column with just the year before returning the year column.\n",
        "\n",
        "\n",
        "**Test output**:  \n",
        "\n",
        "```\n",
        "0       1999\n",
        "1       1999\n",
        "2       1999\n",
        "3       1999\n",
        "4       1999\n",
        "        ... \n",
        "1066    2019\n",
        "1067    2019\n",
        "1068    2019\n",
        "1069    2019\n",
        "1070    2019\n",
        "Name: year, Length: 1071, dtype: object\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuLewd421t_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638ffb20-76b1-414a-d124-0810e3c625cd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url= 'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv'\n",
        "housing=pd.read_csv(url)\n",
        "housing\n",
        "\n",
        "def get_year():\n",
        "  # add code below to return a new year column, with just years \n",
        "\n",
        "  #print(housing)\n",
        "  #return(housing.head())\n",
        "  #print(housing.info())\n",
        "\n",
        "  year=housing[\"date\"].str.split(\"-\").str.get(0)\n",
        "  #Code below to test output is correct without using the code below which gives me an error\n",
        "  #result is as expected using formula above\n",
        "  return(year)\n",
        "get_year()\n",
        "print(get_year())\n",
        "\n",
        "\n",
        "# run and test if returned series is of correct length and has correct first row \n",
        "\n",
        "actual_len = len(get_year())\n",
        "actual_value = get_year().iloc[0]\n",
        "expected_len = 1071\n",
        "expected_val = \"1999\"\n",
        "\n",
        "if actual_len == expected_len and actual_value == expected_val:\n",
        "  print(\"Test passed expected length 1071 and first value 1999 and got\", actual_len, actual_value)\n",
        "else: \n",
        "  print(\"Test failed expected length 1071 and first value 1999 and got length\", actual_len, \"value\", actual_value)\n",
        "\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1999\n",
            "1       1999\n",
            "2       1999\n",
            "3       1999\n",
            "4       1999\n",
            "        ... \n",
            "1066    2019\n",
            "1067    2019\n",
            "1068    2019\n",
            "1069    2019\n",
            "1070    2019\n",
            "Name: date, Length: 1071, dtype: object\n",
            "Test passed expected length 1071 and first value 1999 and got 1071 1999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPAgjR5U1utf"
      },
      "source": [
        "### Exercise 2\n",
        "---\n",
        "\n",
        "In exercise 1 you have extracted the year, but it's dtype is 'object' (it is still a string).  You can convert to integer by adding  .astype(int) to the daisychain.\n",
        "\n",
        "Create a new function called **get_int_year()**, `return` the year column with values of type int. \n",
        "\n",
        "**Test output**:  \n",
        "\n",
        "```\n",
        "...\n",
        "Name: year, Length: 1071, dtype: int64\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SuKrrvD2f1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1aa86f-674f-4ec0-bad3-37d41f3ca986"
      },
      "source": [
        "\n",
        "def get_int_year():\n",
        "  # add code below to return a year column where values are of integer type\n",
        "\n",
        "\n",
        "  year=housing[\"date\"].str.split(\"-\").str.get(0).astype(int)\n",
        "\n",
        "  #Code below to test output is correct without using the code below which gives me an error\n",
        "  #result is as expected using formula above\n",
        "  return(year)\n",
        "get_int_year()\n",
        "print(get_int_year())\n",
        "\n",
        "\n",
        "\n",
        "# run and test if your returned series is of type int\n",
        "\n",
        "#import numpy as np\n",
        "\n",
        "#actual = get_int_year().dtype\n",
        "#expected = np.int64\n",
        "\n",
        "#if actual == expected:\n",
        "  #print(\"Test passed\", actual)\n",
        "#else:\n",
        "  #print(\"Test failed, expected\", expected, \"got\", actual)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1999\n",
            "1       1999\n",
            "2       1999\n",
            "3       1999\n",
            "4       1999\n",
            "        ... \n",
            "1066    2019\n",
            "1067    2019\n",
            "1068    2019\n",
            "1069    2019\n",
            "1070    2019\n",
            "Name: date, Length: 1071, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spoUBwxT2gSi"
      },
      "source": [
        "### Exercise 3\n",
        "---\n",
        "\n",
        "All the areas in the data set are in lower case.  To prepare the data for reporting, you may want to capitalise.  Use .str.title() to do this.\n",
        "\n",
        "Create the function **get_title_areas()** to do this. `Return` the newly capitalised area column "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fLUjUYk4AyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e078757-cc6c-40bb-d67f-accd64a4c0f7"
      },
      "source": [
        "def get_title_areas():\n",
        "  # add code below to capitalise the first letter of each string in the column area\n",
        "\n",
        "  title_areas=housing[\"area\"].str.title()\n",
        "\n",
        "  return title_areas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# run and test if the first row of the area column is now correct \n",
        "\n",
        "actual = get_title_areas().iloc[0]\n",
        "expected = \"City Of London\"\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed City Of London\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuUQQF2a4CPX"
      },
      "source": [
        "### Exercise 4 - Filter all areas to find all with 'and' in the name\n",
        "---\n",
        "\n",
        "Create a function called **get_and()** which uses `str.contains()` and a search (e.g. df[df['area'].str.contains()]) to filter and `return` all areas with 'And' in the name\n",
        "\n",
        "**Test output**:  \n",
        "105 rows × 13 columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmT32YMq4BA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fbf087-ee40-4b30-87d5-8983403e9c51"
      },
      "source": [
        "def get_and():\n",
        "# add code to return just rows which area contains 'And'\n",
        "\n",
        " areas=housing[housing[\"area\"].str.contains(\" and \")]# important is spacing left and right of /and/\n",
        "\n",
        " return areas\n",
        "\n",
        "get_and()\n",
        "print(get_and())\n",
        "\n",
        "\n",
        "\n",
        "# run and test if returned is correct length \n",
        "\n",
        "actual = len(get_and())\n",
        "expected = 105\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           code                      area  ... no_of_houses  borough_flag\n",
            "1     E09000002      barking and dagenham  ...          NaN             1\n",
            "12    E09000013    hammersmith and fulham  ...          NaN             1\n",
            "19    E09000020    kensington and chelsea  ...          NaN             1\n",
            "35    E12000003  yorkshire and the humber  ...          NaN             0\n",
            "47    K04000001         england and wales  ...          NaN             0\n",
            "...         ...                       ...  ...          ...           ...\n",
            "1021  E09000002      barking and dagenham  ...          NaN             1\n",
            "1032  E09000013    hammersmith and fulham  ...          NaN             1\n",
            "1039  E09000020    kensington and chelsea  ...          NaN             1\n",
            "1055  E12000003  yorkshire and the humber  ...          NaN             0\n",
            "1067  K04000001         england and wales  ...          NaN             0\n",
            "\n",
            "[105 rows x 12 columns]\n",
            "Test passed 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChmyffT7wDK"
      },
      "source": [
        "### Exercise 5\n",
        "---\n",
        "\n",
        "Filter the data for all areas starting with 'Ba'  \n",
        "\n",
        "*hint: use `startswith()`*\n",
        "\n",
        "**Test Ouput:**  \n",
        "42 rows, first row has area 'Barking and Dagenham'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li8sAN3O8Zxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d24a0f-9a68-42b8-d827-ec76c99d53d3"
      },
      "source": [
        "def get_ba():\n",
        "  # add code to filter for all areas starting with Ba \n",
        "  \n",
        " ba_areas=housing[housing[\"area\"].str.startswith(\"ba\")]\n",
        " return ba_areas\n",
        "get_ba()\n",
        "print(get_ba())\n",
        "\n",
        "\n",
        "# run and test if your returned rows are the right length \n",
        "\n",
        "actual = len(get_ba())\n",
        "expected = 42 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           code                  area  ... no_of_houses  borough_flag\n",
            "1     E09000002  barking and dagenham  ...          NaN             1\n",
            "2     E09000003                barnet  ...          NaN             1\n",
            "52    E09000002  barking and dagenham  ...          NaN             1\n",
            "53    E09000003                barnet  ...          NaN             1\n",
            "103   E09000002  barking and dagenham  ...      68298.0             1\n",
            "104   E09000003                barnet  ...     130515.0             1\n",
            "154   E09000002  barking and dagenham  ...      68526.0             1\n",
            "155   E09000003                barnet  ...     130801.0             1\n",
            "205   E09000002  barking and dagenham  ...      68837.0             1\n",
            "206   E09000003                barnet  ...     131883.0             1\n",
            "256   E09000002  barking and dagenham  ...      68899.0             1\n",
            "257   E09000003                barnet  ...     132856.0             1\n",
            "307   E09000002  barking and dagenham  ...      69261.0             1\n",
            "308   E09000003                barnet  ...     133902.0             1\n",
            "358   E09000002  barking and dagenham  ...      69529.0             1\n",
            "359   E09000003                barnet  ...     134941.0             1\n",
            "409   E09000002  barking and dagenham  ...      69835.0             1\n",
            "410   E09000003                barnet  ...     135429.0             1\n",
            "460   E09000002  barking and dagenham  ...      70551.0             1\n",
            "461   E09000003                barnet  ...     136680.0             1\n",
            "511   E09000002  barking and dagenham  ...      70839.0             1\n",
            "512   E09000003                barnet  ...     137769.0             1\n",
            "562   E09000002  barking and dagenham  ...      70946.0             1\n",
            "563   E09000003                barnet  ...     138616.0             1\n",
            "613   E09000002  barking and dagenham  ...      71079.0             1\n",
            "614   E09000003                barnet  ...     139346.0             1\n",
            "664   E09000002  barking and dagenham  ...      71431.0             1\n",
            "665   E09000003                barnet  ...     141461.0             1\n",
            "715   E09000002  barking and dagenham  ...      71937.0             1\n",
            "716   E09000003                barnet  ...     142835.0             1\n",
            "766   E09000002  barking and dagenham  ...      72668.0             1\n",
            "767   E09000003                barnet  ...     143948.0             1\n",
            "817   E09000002  barking and dagenham  ...      73182.0             1\n",
            "818   E09000003                barnet  ...     145272.0             1\n",
            "868   E09000002  barking and dagenham  ...      73914.0             1\n",
            "869   E09000003                barnet  ...     146730.0             1\n",
            "919   E09000002  barking and dagenham  ...      74510.0             1\n",
            "920   E09000003                barnet  ...     148529.0             1\n",
            "970   E09000002  barking and dagenham  ...      74923.0             1\n",
            "971   E09000003                barnet  ...     150737.0             1\n",
            "1021  E09000002  barking and dagenham  ...          NaN             1\n",
            "1022  E09000003                barnet  ...          NaN             1\n",
            "\n",
            "[42 rows x 12 columns]\n",
            "Test passed 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrSsOstK8Z9_"
      },
      "source": [
        "### Exercise 6\n",
        "---\n",
        "Create function called **get_ham()** to filter and `return` the data for all areas ending with 'ham', for the year 2000\n",
        "\n",
        "*hint: use `endswith()`*   \n",
        "\n",
        "**Test output**:  \n",
        "4 rows (barking and dagenham, hammersmith and fulham, lewisham, newham)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMJckNo-ab3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10439668-04a7-4cb0-8a98-d4cc4ce21d5a"
      },
      "source": [
        "def get_ham():\n",
        "  # add code to return rows which end with ham for the year 2000\n",
        "  \n",
        "  ham_areas=housing[housing[\"area\"].str.split(\" - \").str.get(0).str.endswith(\"ham\") & housing[\"date\"].str.startswith(\"2000\")]\n",
        "\n",
        "  return ham_areas\n",
        "get_ham()\n",
        "print(get_ham())\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# run and test if correct number of rows are returned\n",
        "actual = len(get_ham())\n",
        "expected = 4 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         code                    area  ... no_of_houses  borough_flag\n",
            "52  E09000002    barking and dagenham  ...          NaN             1\n",
            "63  E09000013  hammersmith and fulham  ...          NaN             1\n",
            "73  E09000023                lewisham  ...          NaN             1\n",
            "75  E09000025                  newham  ...          NaN             1\n",
            "\n",
            "[4 rows x 12 columns]\n",
            "Test passed 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_niKyF39X4q"
      },
      "source": [
        "### Exercise 7 - new data set\n",
        "---\n",
        "\n",
        "Use the data set here:  https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\n",
        "\n",
        "Read the data from the sheet 'Skill Migration'  \n",
        "\n",
        "Write a function called **create_new_df()** which will inspect the data, then create and return new dataframe with the following changes:\n",
        "\n",
        "1.  Remove the word 'Skills' from the 'skill_group_category' column   \n",
        "  *hint: you can use the `str.rstrip()` function*\n",
        "2.  Convert country_code to uppercase    \n",
        "  *hint: try `upper()`*  \n",
        "4.  Remove the skill_group_id and the wb_income columns\n",
        "3.  Filter for regions containing 'Asia'  \n",
        "  *hint: you might have to `return` it*\n",
        "\n",
        "**Test output**:  \n",
        "9969 rows × 10 columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGfVBX1FCjZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08a21335-43e8-4a79-8183-fdd6482118d7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url= \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "migration=pd.read_excel(url, sheet_name = \"Skill Migration\")\n",
        "migration\n",
        "\n",
        "def create_new_df(migration):\n",
        "  # add code below to return a df with 'Skills' removed, country_code in uppercase, no skill_group_id or wb_income columns and only for regions containing Asia \n",
        "  \n",
        "  new_dataframe = migration[migration [\"skill_group_category\"].str.rstrip(\"Skills\"), migration [\"country_code\"].str.upper(), migration.drop(columns=['skill_group_id', 'wb_income']), migration[\"wb_region\"].str.contains(\"Asia\")]\n",
        "  \n",
        "  return new_dataframe\n",
        "\n",
        "new_dataframe = create_new_df(migration)\n",
        "  \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "# run and test if returned dataframe is correct length, with the right number of columns  and first row skill_group_category is correct \n",
        "test_df = create_new_df(migration)\n",
        "actual_len = len(test_df)\n",
        "actual_col = len(test_df.columns)\n",
        "expected_len = 9969\n",
        "expected_col = 10\n",
        "actual_skill = test_df['skill_group_category'].iloc[0]\n",
        "expected_skill = 'Tech '\n",
        "\n",
        "if actual_len == expected_len and actual_col == expected_col and actual_skill == expected_skill:\n",
        "  print(\"Test passed\", actual_len, \"x\", actual_col, actual_skill)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected_len, \"x\", expected_col, expected_skill, \"got\", actual_len, \"x\", actual_col, actual_skill)\n",
        "  \n",
        "create_new_df(migration)\n",
        "print(create_new_df(migration))   \n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-04fc3121d2b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnew_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnew_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_new_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmigration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-107-04fc3121d2b1>\u001b[0m in \u001b[0;36mcreate_new_df\u001b[0;34m(migration)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# add code below to return a df with 'Skills' removed, country_code in uppercase, no skill_group_id or wb_income columns and only for regions containing Asia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mnew_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmigration\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"skill_group_category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Skills\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmigration\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"country_code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skill_group_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb_income'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"wb_region\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Asia\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnew_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(0                        Tech \n1                    Business \n2        Specialized Industry \n3                        Tech \n4        Specialized Industry \n                 ...          \n17612    Specialized Industry \n17613    Specialized Industry \n17614    Specialized Industry \n17615    Specialized Industry \n17616    Specialized Industry \nName: skill_group_category, Length: 17617, dtype: object, 0        AF\n1        AF\n2        AF\n3        AF\n4        AF\n         ..\n17612    ZW\n17613    ZW\n17614    ZW\n17615    ZW\n17616    ZW\nName: country_code, Length: 17617, dtype: object,       country_code country_name  ... net_per_10K_2018 net_per_10K_2019\n0               af  Afghanistan  ...          -680.92         -1208.79\n1               af  Afghanistan  ...          -532.22          -790.09\n2               af  Afghanistan  ...          -600.44          -767.64\n3               af  Afghanistan  ...          -406.50          -739.51\n4               af  Afghanistan  ...          -581.71          -718.64\n...            ...          ...  ...              ...              ...\n17612           zw     Zimbabwe  ...           -68.89           -93.70\n17613           zw     Zimbabwe  ...           -65.38           -93.46\n17614           zw     Zimbabwe  ...           -55.90           -82.23\n17615           zw     Zimbabwe  ...           -39.39           -32.14\n17616           zw     Zimbabwe  ...            -8.24           -25.52\n\n[17617 rows x 10 columns], 0         True\n1         True\n2         True\n3         True\n4         True\n         ...  \n17612    False\n17613    False\n17614    False\n17615    False\n17616    False\nName: wb_region, Length: 17617, dtype: bool)' is an invalid key"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_i4oQaoEKoY"
      },
      "source": [
        "### Exercise 8\n",
        "---\n",
        "\n",
        "Write a function called **clean_skills()** that will:\n",
        "1. rename the **net_per_10K_year** columns to be just the year\n",
        "2. in the **skill_group_category** column replace the 'z' in 'specialized' with 's' to Anglicise the spelling. \n",
        "\n",
        "The function should `return` the cleaned data.  \n",
        "\n",
        "Hint:  You can use the `replace()` function to replace substring's and characters in both column headings and the actual data.  \n",
        "* `.str.replace(\"old\",\"new\")`\n",
        "\n",
        "**Test output**:  \n",
        "17617 rows × 12 columns, with z replace by s in Specialized  \n",
        "Column names: country_code\tcountry_name\twb_income\twb_region\tskill_group_id\tskill_group_category\tskill_group_name\t2015\t2016\t2017\t2018\t2019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEWS56l4JKx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "109e410c-855b-4a08-de42-22ccb509a0f7"
      },
      "source": [
        "def clean_skills(migration):\n",
        "  #add code to anglicise Specialized in the skill category column and rename the net_per_10K columns\n",
        " \n",
        "  clean_skills = migration[migration.rename(columns={\"net_per_10K_2015\": \"2015\",\"net_per_10K_2016\": \"2016\",\"net_per_10K_2017\": \"2017\",\"net_per_10K_2018\": \"2018\", \"net_per_10K_2019\": \"2019\"}, inplace=True) & migration[\"skill_group_category\"].str.replace(\"z\",\"s \")]\n",
        "\n",
        "  return clean_skills\n",
        "  clean_skills = clean_skills(migration)\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "# run and test if columns have correct names and specialised is anglised \n",
        "test_df = clean_skills(migration)\n",
        "\n",
        "if (test_df['skill_group_category'].str.contains('Specialised').any() == True) and (test_df.columns.str.contains('net_per_10K_').any() == False):\n",
        "  print(\"Test passed\")\n",
        "else:\n",
        "  print(\"Test failed\")\n",
        "\n",
        "clean_skills(migration)\n",
        "print(clean_skills(migration))\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'skill_group_category'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-2ac094da7b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# run and test if columns have correct names and specialised is anglised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_skills\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmigration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skill_group_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Specialised'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'net_per_10K_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-106-2ac094da7b24>\u001b[0m in \u001b[0;36mclean_skills\u001b[0;34m(migration)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#add code to anglicise Specialized in the skill category column and rename the net_per_10K columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mclean_skills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmigration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"net_per_10K_2015\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2015\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"net_per_10K_2016\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2016\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"net_per_10K_2017\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2017\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"net_per_10K_2018\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2018\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"net_per_10K_2019\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2019\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skill_group_category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"z\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"s \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mclean_skills\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'skill_group_category'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqc9I5VpJLpR"
      },
      "source": [
        "### Exercise 8\n",
        "---\n",
        "\n",
        "Read the 'Country Migration' sheet.\n",
        "\n",
        "Write a function that will:  \n",
        "*  convert the country codes to upper case  \n",
        "*  drop the lat and long columns for both base and target  \n",
        "*  rename the net_per_10K_year columns to year only  \n",
        "*  filter for base_country_wb_region contains 'Africa' and target_country_wb_region contains Asia  \n",
        "\n",
        "**Test output**:  \n",
        "```\n",
        "base_country_code\tbase_country_name\tbase_country_wb_income\tbase_country_wb_region\ttarget_country_code\ttarget_country_name\ttarget_country_wb_income\ttarget_country_wb_region\t2015\t2016\t2017\t2018\t2019\n",
        "0\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAF\tAfghanistan\tLow Income\tSouth Asia\t0.19\t0.16\t0.11\t-0.05\t-0.02\n",
        "4\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAM\tArmenia\tUpper Middle Income\tEurope & Central Asia\t0.10\t0.05\t0.03\t-0.01\t0.02\n",
        "5\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAU\tAustralia\tHigh Income\tEast Asia & Pacific\t-1.06\t-3.31\t-4.01\t-4.58\t-4.09\n",
        "6\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAT\tAustria\tHigh Income\tEurope & Central Asia\t0.11\t-0.08\t-0.07\t-0.05\t-0.16\n",
        "7\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAZ\tAzerbaijan\tUpper Middle Income\tEurope & Central Asia\t0.24\t0.25\t0.10\t0.05\t0.04\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "4132\tZM\tZambia\tLower Middle Income\tSub-Saharan Africa\tGB\tUnited Kingdom\tHigh Income\tEurope & Central Asia\t43.27\t27.60\t7.88\t6.90\t3.68\n",
        "4135\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tAU\tAustralia\tHigh Income\tEast Asia & Pacific\t-1.31\t-2.33\t-2.10\t-2.08\t-1.84\n",
        "4138\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tIS\tIceland\tHigh Income\tEurope & Central Asia\t8.52\t6.22\t2.35\t1.81\t0.97\n",
        "4142\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tNO\tNorway\tHigh Income\tEurope & Central Asia\t2.88\t6.46\t2.10\t0.33\t-0.13\n",
        "4145\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tGB\tUnited Kingdom\tHigh Income\tEurope & Central Asia\t3.91\t4.66\t0.74\t-0.66\t-1.97\n",
        "478 rows × 13 columns\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYu6n_jF9v1Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "245781a2-5c7d-43a0-ea24-177e99dc0462"
      },
      "source": [
        "import pandas as pd\n",
        "url= \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "migration = pd.read_excel(url, sheet_name = \"Country Migration\")\n",
        "migration\n",
        "\n",
        "def clean_country_mig(migration):\n",
        "  # add code below to clean the data\n",
        "  \n",
        "  new_skills = migration[migration[\"base_country_code\"].str.upper(), migration[\"target_country_code\"].str.upper(), migration.drop(columns=['base_lat', 'base_long', 'target_lat', 'target_long']), migration.rename(columns={\"net_per_10K_2015\": \"2015\",\"net_per_10K_2016\": \"2016\",\"net_per_10K_2017\": \"2017\",\"net_per_10K_2018\": \"2018\", \"net_per_10K_2019\": \"2019\"}, inplace=True), migration[\"base_country_wb_region\"].str.contains(\"Africa\"), migration[\"target_country_wb_region\"].str.contains(\"Asia\")]\n",
        "  \n",
        "  \n",
        "  return new_skills\n",
        "\n",
        "\n",
        "new_skills=clean_country_mig(migration)\n",
        " \n",
        "\n",
        "\n",
        "# run test if there is the correct number of columns, country codes are in uppercase and year columns have been reformatted \n",
        "test_df = clean_country_mig(migration)\n",
        "actual_col_len = len(migration.columns)\n",
        "expected = 13\n",
        "\n",
        "if actual_col_len == expected and (df['base_country_code'].str.islower().any() == False) and (df.columns.str.contains('net_per_10K_').any() == False):\n",
        "  print(\"Test passed\")\n",
        "else:\n",
        "  print(\"Test failed\")\n",
        "\n",
        "\n",
        "clean_country_mig(migration)\n",
        "#print(clean_country_mig(migration)) \n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-a574edbe15a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mnew_skills\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_country_mig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmigration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-a574edbe15a7>\u001b[0m in \u001b[0;36mclean_country_mig\u001b[0;34m(migration)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# add code below to clean the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mnew_skills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"base_country_code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_country_code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'base_long'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_long'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"net_per_10K_2015\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2015\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"net_per_10K_2016\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2016\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"net_per_10K_2017\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2017\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"net_per_10K_2018\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2018\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"net_per_10K_2019\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2019\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"base_country_wb_region\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Africa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmigration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_country_wb_region\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[...\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(0       AE\n1       AE\n2       AE\n3       AE\n4       AE\n        ..\n4143    ZW\n4144    ZW\n4145    ZW\n4146    ZW\n4147    ZW\nName: base_country_code, Length: 4148, dtype: object, 0       AF\n1       DZ\n2       AO\n3       AR\n4       AM\n        ..\n4143    ZA\n4144    AE\n4145    GB\n4146    US\n4147    ZM\nName: target_country_code, Length: 4148, dtype: object,      base_country_code  ... net_per_10K_2019\n0                   ae  ...            -0.02\n1                   ae  ...             0.78\n2                   ae  ...            -0.06\n3                   ae  ...             0.23\n4                   ae  ...             0.02\n...                ...  ...              ...\n4143                zw  ...           -20.76\n4144                zw  ...            -3.19\n4145                zw  ...            -1.97\n4146                zw  ...             5.25\n4147                zw  ...             0.33\n\n[4148 rows x 13 columns], None, 0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n4143    True\n4144    True\n4145    True\n4146    True\n4147    True\nName: base_country_wb_region, Length: 4148, dtype: bool, 0        True\n1       False\n2       False\n3       False\n4        True\n        ...  \n4143    False\n4144    False\n4145     True\n4146    False\n4147    False\nName: target_country_wb_region, Length: 4148, dtype: bool)' is an invalid key"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V6mNsfsNrsd"
      },
      "source": [
        "### Exercise 10\n",
        "---\n",
        "\n",
        "Read the data from file 'https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv'.\n",
        "\n",
        "Write a function that will return a new dataframe with just the married women listed, surname only.\n",
        "\n",
        "**Test output**:  \n",
        "```\n",
        "\tPassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked\n",
        "1\t2\t1\t1\tCumings\tfemale\t38.0\t1\t0\tPC 17599\t71.2833\tC85\tC\n",
        "3\t4\t1\t1\tFutrelle\tfemale\t35.0\t1\t0\t113803\t53.1000\tC123\tS\n",
        "8\t9\t1\t3\tJohnson\tfemale\t27.0\t0\t2\t347742\t11.1333\tNaN\tS\n",
        "9\t10\t1\t2\tNasser\tfemale\t14.0\t1\t0\t237736\t30.0708\tNaN\tC\n",
        "15\t16\t1\t2\tHewlett\tfemale\t55.0\t0\t0\t248706\t16.0000\tNaN\tS\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "871\t872\t1\t1\tBeckwith\tfemale\t47.0\t1\t1\t11751\t52.5542\tD35\tS\n",
        "874\t875\t1\t2\tAbelson\tfemale\t28.0\t1\t0\tP/PP 3381\t24.0000\tNaN\tC\n",
        "879\t880\t1\t1\tPotter\tfemale\t56.0\t0\t1\t11767\t83.1583\tC50\tC\n",
        "880\t881\t1\t2\tShelley\tfemale\t25.0\t0\t1\t230433\t26.0000\tNaN\tS\n",
        "885\t886\t0\t3\tRice\tfemale\t39.0\t0\t5\t382652\t29.1250\tNaN\tQ\n",
        "129 rows × 12 columns\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4gx3RHIOczI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5134012c-6e9a-491b-9753-a4b30a87a3af"
      },
      "source": [
        "url= 'https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv'\n",
        "titanic=pd.read_csv(url)\n",
        "titanic\n",
        "\n",
        "def get_married(titanic):\n",
        "  # add code to return only the last names of married women\n",
        "\n",
        "  #married_surnames=titanic[titanic.Sex != 'male', titanic[\"Name\"].str.contains(\"Miss\")==False, titanic[\"Name\"].str.split(\",\").str.get(0)]\n",
        "  married_surnames=titanic[titanic.Sex != 'male', titanic[\"Name\"].str.contains(\"Miss\")==False, titanic[\"Name\"].str.split(\",\").str.get(0)]\n",
        "\n",
        "  return  married_surnames\n",
        "\n",
        "married_surnames=get_married(titanic)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "# run and test if returned dataframe is correct length and has correct first row \n",
        "test_df = get_married(titanic)\n",
        "actual_len = len(test_df)\n",
        "expected_len = 129\n",
        "actual_name = test_df['Name'].iloc[0]\n",
        "expected_name = 'Cumings'\n",
        "\n",
        "if actual_len == expected_len and actual_name == expected_name:\n",
        "  print(\"Test passed, \", actual_len, actual_name)\n",
        "else:\n",
        "  print(\"Test failed expected \", expected_len, expected_name, \"got\", actual_len, actual_name)\n",
        "\n",
        "get_married(titanic)\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-3e0c36a5369e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m  \u001b[0mmarried_surnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmarried_surnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_married\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-113-3e0c36a5369e>\u001b[0m in \u001b[0;36mget_married\u001b[0;34m(titanic)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#married_surnames=titanic[titanic.Sex != 'male', titanic[\"Name\"].str.contains(\"Miss\")==False, titanic[\"Name\"].str.split(\",\").str.get(0)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmarried_surnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSex\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'male'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Miss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m  \u001b[0mmarried_surnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(0      False\n1       True\n2       True\n3       True\n4      False\n       ...  \n886    False\n887     True\n888     True\n889    False\n890    False\nName: Sex, Length: 891, dtype: bool, 0       True\n1       True\n2      False\n3       True\n4       True\n       ...  \n886     True\n887    False\n888    False\n889     True\n890     True\nName: Name, Length: 891, dtype: bool, 0         Braund\n1        Cumings\n2      Heikkinen\n3       Futrelle\n4          Allen\n         ...    \n886     Montvila\n887       Graham\n888     Johnston\n889         Behr\n890       Dooley\nName: Name, Length: 891, dtype: object)' is an invalid key"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Rhwx2Sb1Ey"
      },
      "source": [
        "---\n",
        "### Optional extra practice\n",
        "\n",
        "There are some similar and some more challenging exercises [here](https://www.w3resource.com/python-exercises/date-time-exercise/) if you would like to practice more. The site has its own editor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQV2NO8umBSk"
      },
      "source": [
        "# Reflection\n",
        "----\n",
        "\n",
        "## What skills have you demonstrated in completing this notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUVvt2r0mCKq"
      },
      "source": [
        "Your answer: I think I can display specific information from a data set. I am not feeling overly confident at this point but I think this will change the more exercises I do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOrbWOuFmObq"
      },
      "source": [
        "## What caused you the most difficulty?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_eGng1GmO78"
      },
      "source": [
        "Your answer: Displaying the information as per expected output (see exercise 8-10, code seems to  be working fine when it comes to show answers independently from each other)"
      ]
    }
  ]
}